{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import tensorflow as tf\n",
    "from  read_proces_data import *\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# create lstm cell in tensorflow\n",
    "hidden_units = 128\n",
    "lstm_cell = tf.contrib.rnn.BasicLSTMCell(num_units =\\\n",
    "        hidden_units,state_is_tuple=True)\n",
    "\n",
    "batch_size = 20\n",
    "max_seq = 3260\n",
    "feature_vec_len = 57\n",
    "x = tf.placeholder(tf.float32, shape = [batch_size,max_seq,feature_vec_len])\n",
    "s_len = tf.placeholder(tf.int32,shape=[batch_size])\n",
    "# run lstm over different sequence length\n",
    "output_, state = tf.nn.dynamic_rnn(\\\n",
    "        lstm_cell,\\\n",
    "        x,\\\n",
    "#        initial_state = i_state,\\\n",
    "        sequence_length=s_len,\\\n",
    "        dtype=tf.float32)\n",
    "# take all batch, last output of each batch and full output vector\n",
    "def take_subarray(array , index):\n",
    "    return array[range(0,batch_size),index-1]\n",
    "output = tf.py_func(take_subarray,[output_,s_len],tf.float32)\n",
    "#print output\n",
    "# define final output value\n",
    "target_value = tf.placeholder(tf.float32, shape=[batch_size])\n",
    "# define weights and bias from output of lstm cell to network final output\n",
    "rv1 = tf.truncated_normal([lstm_cell.output_size, 2 * lstm_cell.output_size],\\\n",
    "        stddev=0.1,dtype=tf.float32)\n",
    "Wo1 = tf.Variable(rv1,dtype=tf.float32)\n",
    "\n",
    "rv2 = tf.truncated_normal([2 * lstm_cell.output_size, 1],\\\n",
    "        stddev=0.1,dtype=tf.float32)\n",
    "Wo2 = tf.Variable(rv2,dtype=tf.float32)\n",
    "\n",
    "rb1 = tf.constant(0.1,shape=[2 * lstm_cell.output_size],dtype=tf.float32)\n",
    "b1 = tf.Variable(rb1,dtype=tf.float32)\n",
    "\n",
    "rb2 = tf.constant(0.1,shape=[1],dtype=tf.float32)\n",
    "b2 = tf.Variable(rb2,dtype=tf.float32)\n",
    "# initialize variables\n",
    "# calculate final output\n",
    "\n",
    "s1  = tf.matmul(output, Wo1) + b1\n",
    "o1 = tf.nn.relu(s1)\n",
    "logits  = tf.matmul(o1, Wo2) + b2\n",
    "observed = tf.sigmoid(logits)\n",
    "#observed = tf.nn.relu(logits)\n",
    "\n",
    "# calculate cost as calculated in logistic classification.\n",
    "logistic_cost = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(\\\n",
    "        labels = target_value, logits = tf.reshape(logits,[batch_size])))\n",
    "#cost = tf.reduce_mean(-1.0 * target_value * tf.log(observed) - \\\n",
    "#        (1 - target_value) * tf.log(1 - observed))\n",
    "#cost = tf.reduce_mean(-1 * target_value * tf.log(observed))\n",
    "#cost = tf.reduce_mean(tf.square(target_value - observed))\n",
    "# optimize the cost\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(logistic_cost)\n",
    "def threshold_fn(array):\n",
    "    return array >= 0.50\n",
    "obser = tf.py_func(threshold_fn,[observed], tf.bool)\n",
    "observe = tf.cast(obser,tf.float32)\n",
    "\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finding max seq len in train set\n",
      "finding max seq len in test set\n",
      "max s_len found\n",
      "3259\n"
     ]
    }
   ],
   "source": [
    "# find max no of times to roll back\n",
    "max_seq_len = find_max_seq_len()\n",
    "print max_seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0\n",
      "cost 0.713331\n",
      "f1-score is 0.642857\n",
      "area under curve is 0.500000\n",
      "accuracy 0.500000\n",
      " \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (0, 3260, 57) for Tensor u'Placeholder:0', which has shape '(20, 3260, 57)'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-fb914c1f7724>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m                         \u001b[0myfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobserve\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m                            \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0minde_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m                             \u001b[0ms_len\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mseq_len\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m                         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/gnl/TF/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, feed_dict, session)\u001b[0m\n\u001b[1;32m    604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m     \"\"\"\n\u001b[0;32m--> 606\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_eval_using_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    607\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/gnl/TF/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36m_eval_using_default_session\u001b[0;34m(tensors, feed_dict, graph, session)\u001b[0m\n\u001b[1;32m   3926\u001b[0m                        \u001b[0;34m\"the tensor's graph is different from the session's \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3927\u001b[0m                        \"graph.\")\n\u001b[0;32m-> 3928\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3930\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/gnl/TF/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 789\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    790\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/gnl/TF/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    973\u001b[0m                 \u001b[0;34m'Cannot feed value of shape %r for Tensor %r, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m                 \u001b[0;34m'which has shape %r'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 975\u001b[0;31m                 % (np_val.shape, subfeed_t.name, str(subfeed_t.get_shape())))\n\u001b[0m\u001b[1;32m    976\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    977\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Tensor %s may not be fed.'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot feed value of shape (0, 3260, 57) for Tensor u'Placeholder:0', which has shape '(20, 3260, 57)'"
     ]
    }
   ],
   "source": [
    "# number of times to iterate over whole training dataset\n",
    "iter_over_files =  1\n",
    "for itera in range(0, iter_over_files):\n",
    "    for file_ in file_dir:\n",
    "        # get features from current indexed file\n",
    "        features = get_train_data(file_)\n",
    "        # get target values corresponding to this file\n",
    "        target_values = get_target_values(file_)\n",
    "        # training features is np array with max size and padding\n",
    "        training_features, seq_len = prepare_data(features, max_seq_len)\n",
    "        # scale features to have 0 mean and 1 variance\n",
    "        scaled_features = feature_scaling(training_features, batch_size,\\\n",
    "                seq_len)\n",
    "        # check if there is any NaN or Inf entries in data\n",
    "        isnan = np.any(np.isnan(scaled_features))\n",
    "        if True == isnan:\n",
    "            print \"nan entry found for file %s\"%file_\n",
    "            continue\n",
    "        isinf = np.any(np.isinf(scaled_features))\n",
    "        if True == isinf:\n",
    "            print \"inf entry found for file %s\"%file_\n",
    "            continue\n",
    "        # find independent components from given features\n",
    "        inde_features = independent_components(scaled_features, batch_size,\\\n",
    "                seq_len)\n",
    "\n",
    "        for i in range(0,10):\n",
    "            tr_fe, sl , tv =\\\n",
    "            sample_data(inde_features,target_values,seq_len,batch_size)\n",
    "\n",
    "            sess.run(train_step, feed_dict = {target_value:tv,\\\n",
    "                    x:tr_fe, s_len:sl})\n",
    "\n",
    "            if i%9 == 0:\n",
    "                print \"iteration %d\"%i\n",
    "                print \"cost %f\"%logistic_cost.eval(feed_dict = {target_value:tv,\\\n",
    "                    x:tr_fe, s_len:sl})\n",
    "\n",
    "                y = observe.eval(feed_dict = {x:tr_fe, s_len:sl})\n",
    "#        print tv\n",
    "#        print y\n",
    "                f1s = metrics.f1_score(tv,y)\n",
    "                print \"f1-score is %f\"%f1s\n",
    "                fpr, tpr, thresholds = metrics.roc_curve(tv, y, pos_label=1)\n",
    "                auc = metrics.auc(fpr,tpr)\n",
    "                print \"area under curve is %f\"%auc\n",
    "                sk_accuracy = metrics.accuracy_score(tv,y)\n",
    "                print \"accuracy %f\"%sk_accuracy\n",
    "                print \" \"\n",
    "                \n",
    "                # evaluate over whole file\n",
    "                y = np.zeros(0)\n",
    "                if \"05\" in file_:\n",
    "                    print file_\n",
    "                    for index in range(0,100,batch_size):\n",
    "                        yfile = observe.eval(feed_dict = {\\\n",
    "                            x:inde_features[index:index+batch_size], \\\n",
    "                            s_len:seq_len[index:index+batch_size]})\n",
    "                        y = np.append(y,yfile)\n",
    "                else:\n",
    "                    for index in range(0,100,batch_size):\n",
    "                        yfile = observe.eval(feed_dict = {\\\n",
    "                            x:inde_features[index:index+batch_size], \\\n",
    "                            s_len:seq_len[index:index+batch_size]})\n",
    "                        y = np.append(y,yfile)\n",
    "\n",
    "                f1score = metrics.f1_score(target_values,y)\n",
    "                print \"f1-score of file is %f\"%f1score\n",
    "                fprr, tprr, thresholds = metrics.roc_curve(target_values, y, pos_label=1)\n",
    "                aucc = metrics.auc(fprr,tprr)\n",
    "                print \"area under curve of file is %f\"%aucc\n",
    "                sk_acc = metrics.accuracy_score(target_values,y)\n",
    "                print \"accuracy of file is %f\"%sk_acc\n",
    "                print \" \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
